[
  
  {
    "title": "Desactivar error multipath Ubuntu",
    "url": "/posts/desactivar-error-multipath/",
    "categories": "linux, ubuntu",
    "tags": "linux, ubuntu",
    "date": "2024-04-18 10:00:00 +0200",
    "content": "Trabajando con algún servidor Ubuntu, ya sea la versión 20.04 o 22.04, me he fijado que en los logs suele dar un error relacionado con multipath.  A mi por lo menos me molesta mucho a la hora de tratar con el fichero /var/log/syslog, porque llena el log de líneas que te distraen, por lo que en este post veremos cómo quitar dichos mensajes.  Lo primero que haremos es editar el fichero /etc/multipath.conf y dejaremos el fichero de la siguiente forma:  defaults {     user_friendly_names yes }  blacklist {     devnode \"^(ram|raw|loop|fd|md|dm-|sr|scd|st)[0-9]*\"     devnode \"^sd[a-z]?[0-9]*\" }   Donde en el segundo devnode pondremos sd[...] si corresponde con el nombre de nuestro disco, si tenemos otro, ponemos el que nos muestre el comando lsblk.  Después de esto reiniciamos el servicio de multipath con sudo systemctl restart multipath-tools para aplicar los cambios que hemos hecho.  Con todo esto, ya dejarán de salir esos dichosos mensajes.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Agregar disco a LVM",
    "url": "/posts/agregar-disco-lvm/",
    "categories": "linux, lvm",
    "tags": "linux, lvm",
    "date": "2024-04-01 10:00:00 +0200",
    "content": "En posts anteriores (ha pasado tiempo desde entonces, debería darle una vuelta y actualizarlo) vimos cómo ampliar un disco LVM que ya teníamos, así que en este post vamos a añadir un nuevo disco LVM de nuestro servidor Linux.  Para empezar, vamos a añadir un disco en nuestro servidor utilizando nuestra herramienta de virtualización, ya sea VMware, VirtualBox, KVM, etcétera. Damos por hecho que sabéis hacer esta parte, porque cada herramienta es un mundo.  Una vez hecho esto, vamos al servidor en cuestión e iremos ejecutando los comandos que voy indicando, los cuales pondré con la explicación de lo que hace cada uno:  lsblk # Para listar los discos físicos, en mi caso es el disco /dev/vdb   Vamos a usar la herramienta cfdisk hacer el particionado del disco, también podemos usar fdisk, pero me resulta más cómodo esta herramienta. Cada en el siguiente bloque de código pondré las opciones a elegir en cada línea de comentario.  sudo cfdisk /dev/vdb  # Elegimos gpt # Seleccionamos [New] y el tamaño de la partición, en mi caso 5G # Seleccionamos [Type] y buscamos \"Linux LVM\" # Seleccionamos ahora [Write] y confirmamos los cambios escribiendo \"yes\" # Cerramos el programa con [Quit]   Una vez creado la partición del disco, vamos a crear la partición física LVM, el grupo y la partición lógica.  sudo pvcreate /dev/vdb1 # Creamos la partición física sudo vgcreate vg_test /dev/vdb1 # Creamos el grupo indicando la partición física sudo lvcreate -n lv_test -l +100%FREE vg_test # Creamos la partición lógica indicando el tamaño del mismo y el grupo al que va asociado sudo lvchange -ay /dev/vg_test/lv_test # Activamos la partición física. IMPORTANTE: esto sólo se hace la primera vez que creamos la partición, para ampliarla no es necesario sudo mkfs.xfs /dev/mapper/vg_test-lv_test # Le damos formato, en este XFS sudo mkdir /data01/ # Creamos una carpeta donde montaremos el disco   Lo pongo fuera del código para remarcarlo. IMPORTANTE: esto sólo se hace la primera vez que creamos la partición, para ampliarla no es necesario.  Ahora vamos a configurar el fichero /etc/fstab para que el disco se monte automáticamente en el servidor cada vez que arranque.  echo \"/dev/mapper/vg_test-lv_test /data01/ xfs defaults 0 0\" | sudo tee -a /etc/fstab # Con esto añadiremos directamente la línea en el fichero sin tener que editarlo   De momento no se ha montado la partición, si no queremos/tenemos que reiniciar el servidor, podemos ejecutar el comando sudo mount -a para que lo haga en caliente.  Una vez hecho, si ejecutamos el comando df -h, ya veremos la partición LVM con el tamaño del disco, el uso del mismo, lo que tiene disponible, su porcentaje y sobre qué carpeta está montado:  [vagrant@freeipa-server01 ~]$ df -h Filesystem                   Size  Used Avail Use% Mounted on devtmpfs                     4.0M     0  4.0M   0% /dev tmpfs                        886M  171M  716M  20% /dev/shm tmpfs                        355M  9.5M  345M   3% /run /dev/mapper/rocky-root       125G  3.1G  122G   3% / /dev/vda1                   1014M  202M  813M  20% /boot tmpfs                        178M     0  178M   0% /run/user/1000 /dev/mapper/vg_test-lv_test  5.0G   68M  5.0G   2% /data01 [vagrant@freeipa-server01 ~]$   Con esto ya tendremos el nuevo disco en el servidor para darle el uso que queramos, separar las BBDD, almacenar los logs, etcétera.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Eliminar backups fallidos de Barman",
    "url": "/posts/eliminar-backup-fallidos-barman/",
    "categories": "linux, ubuntu, postgres, backup",
    "tags": "linux, ubuntu, postgres, backup",
    "date": "2024-03-14 09:00:00 +0100",
    "content": "Por si algún casual fallasen varios backups de seguidos, en vez de eliminarlos uno a uno podemos hacer lo siguiente para eliminar todos.  Por si antes de eliminar los backups fallidos quieres saber cuáles hay, tenemos que ejecutar el siguiente comando para que te muestre un listado de lo mismos, donde &lt;server&gt; es el servidor que queremos consultar.  barman list-backups &lt;server&gt; | grep FAILED | awk '{print $2;}'   Una vez identificados, podemos eliminarlos con el siguiente comando.  for bad in $(barman list-backups &lt;server&gt; | grep FAILED | awk '{print $2;}'); do \\ barman delete &lt;server&gt; $bad \\ done   Esto eliminará todos los backups fallidos de dicho servidor.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Restaurar backup de Barman",
    "url": "/posts/restaurar-backup-barman/",
    "categories": "linux, ubuntu, postgres, backup",
    "tags": "linux, ubuntu, postgres, backup",
    "date": "2024-02-12 09:00:00 +0100",
    "content": "En anteriores posts, instalamos y configuramos Barman para que se encargase de las copias de seguridad de nuestras BBDD montadas sobre PostgreSQL. En este veremos cómo restaurar uno de los backups que hayamos hecho.  Para ello seguiremos los siguientes pasos:          Apagaremos el servidor Postgres que será el destino, el comando de ejemplo que se utiliza es la versión 12 sobre un Ubuntu 22.04      systemctl stop postgresql@12-main.service                Hacemos un backup de la carpeta de los datos originales en Postgres, aunque esto no es necesario si en el servidor no hay datos de por sí (si es un servidor nuevo).           Ejecutamos el siguiente comando desde Barman      barman recover \\ --remote-ssh-command \"ssh postgres@&lt;ip_server&gt;\" \\ --target-time=\"2024-01-21 17:00:00.00+00:00\" \\ &lt;id_server&gt; &lt;backup_id&gt; &lt;ruta_destino&gt;           Donde:     &lt;ip_server&gt; es la IP del servidor destino, donde previamente hemos realizado la configuración de las claves de SSH.   --target-time es la fecha de cuando queremos recuperar el backup. He dejado esa fecha para saber el formato que tiene que tener.   &lt;id_server&gt; el nombre del servidor que hemos definido en la configuración del Barman, se puede obtener con el comando barman list-backup all para que te muestre todos los backups disponibles. Un ejemplo sería dbpgn1-pro.   &lt;backup_id&gt; el timestamp del backup que tengamos disponible, también se puede sacar con el comando barman list-backup all. Un ejemplo sería 20240215T200002.   &lt;ruta_destino&gt; la carpeta donde vamos a dejar los datos en el servidor Postgres destino.   Con esto ya podremos iniciar de nuevo el servidor Postgres y ya tendrá los datos disponibles recuperados.  systemctl start postgresql@12-main.service   Este post más corto de lo normal, pero era algo necesario de hacer, porque podemos tener los backups que queramos, pero si no sabemos cómo utilizarlos, de poco nos sirve. Una práctica recomendable a realizar en nuestros entornos productivos es realizar cada cierto tiempo, semestralmente por ejemplo, un simulacro de restauración, para comprobar que nuestros backups no están corruptos el día que lo necesitemos realmente.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Crear una política de contraseñas en FreeIPA",
    "url": "/posts/crear-politica-pass-freeipa/",
    "categories": "linux, ubuntu, rocky, freeipa",
    "tags": "linux, ubuntu, rocky, freeipa",
    "date": "2024-02-09 09:00:00 +0100",
    "content": "A la hora de crear usuarios que usaremos para servicios en nuestro FreeIPA, nos interesa que la contraseña de estos no cambien. Así que lo que haremos en este post es crear una política que evite que caduquen.  Crear grupo  Antes de crear la política, vamos a crear un grupo donde irán los usuarios que queramos que no se les cambie la contraseña cada cierto tiempo y al que asociaremos la política que crearemos más adelante.  En el apartado de Identidad &gt; Grupos de nuestro servidor crearemos un grupo, en mi caso lo llamaré systemusers. El resto de parámetros los dejaremos como están, aunque podéis poner la descripción que queráis.    Crear política contraseña  Para ello nos iremos al apartado Política &gt; Políticas de Contraseña.    Ahí añadiremos una nueva, con el botón a la derecha que pone Agregar, donde pondremos el grupo al que queremos asociar y una prioridad, en mi caso pondré 1, porque quiero que se aplique sobre las demás. Guardamos dando a Agregar y Editar para continuar con la configuración.  En el siguiente pantallazo nos pedirán que pongamos la longitud mínima de contraseña, nº de intentos fallidos y más opciones, pero la que nos interesa es la opción de Vida máxima que es la que estipulará que no caduque nuestra contraseña. Le pondremos el valor a 0 (cero) para que no expire, el resto de valores, podéis ponerlo como queráis realmente, al gusto del consumidor.    Ya sólo será meter usuarios del sistema, o usuarios que no queramos que su contraseña caduque, al grupo que hemos creado anteriormente y tiene asociado la política que acabamos de crear.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar cliente de FreeIPA",
    "url": "/posts/instalar-freeipa-cliente/",
    "categories": "linux, ubuntu, rocky, freeipa",
    "tags": "linux, ubuntu, rocky, freeipa",
    "date": "2024-02-06 09:00:00 +0100",
    "content": "En este post empezaremos a añadir servidores a nuestro dominio local, el cual desplegamos en el anterior post, para poder conectarnos a ellos mediante la autenticación centralizada que nos ofrece IPA.  Para este caso voy a usar de cliente otro Rocky Linux, pero dejaré también los comandos para instalarlo en un Ubuntu.  Antes de empezar a hacer nada en el cliente, vamos a crear un usuario en FreeIPA que sólo se utilice para unir hosts al dominio, ya que nos ayudará a nivel de seguridad y a la hora de la automatización.  Creación rol para añadir equipos al dominio  Los siguiente pasos se hacen desde la UI del servidor de FreeIPA.  Empezamos creando el rol mencionado con los permisos necesarios para poder unir los equipos al dominio y para eso iremos al apartado de Servidor IPA y en la pestaña que sale por defecto, Role-Based Access Control (o sus siglas RBAC), y agregamos uno al que llamaremos Host Enrollment.    Al crearlo, daremos a Agregar y Editar para que nos lleve a la ventana donde podemos configurar los permisos.    Vamos a la pestaña Objeto de servicio y Agregar.    El permiso que vamos a utilizar es Host Administrators.    Creación usuario para añadir equipos al dominio  Ahora vamos a la parte de crear el usuario, por lo que iremos a la parte de Identidad &gt; Usuarios para poder hacerlo, en mi caso llamaré al usuario systemenrollment, y rellenamos los datos que nos solicitan. También daremos a Agregar y Editar para añadir ya el rol al usuario, aunque se puede hacer después sin ningún problema pinchando sobre el nombre del usuario.  Un consejo que os doy aquí es que pongáis una contraseña cualquiera, accedáis con el usuario, ya que os pedirá cambiar la contraseña y ya ahí le ponéis la contraseña final que queráis.      Dentro del apartado del usuario que acabamos de crear, pinchamos sobre la pestaña Roles y agregamos que tenga el rol Host Enrollment.    Añadir equipos al dominio  Una vez tengamos nuestro usuario creado, lo siguiente es instalar el paquete necesario y ejecutar el comando para unirlo al dominio.  Para instalarlo en Rocky Linux el comando sería:  sudo dnf install freeipa-client -y   Y para Ubuntu:  sudo apt install freeipa-client -y      La opción -y es para que se instale automáticamente.   Teniendo ya lo necesario instalado, tenemos que hacer unas configuraciones en el cliente antes de unir el equipo al dominio.  El primero es añadir en /etc/hosts el dominio, quedando de la siguiente manera:  127.0.1.1 freeipa-server02.samurantech.local freeipa-server02   Y la otra configuración a realizar, es cambiar para que el servidor DNS sea el servidor de FreeIPA.  Con esto ya podemos ejecutar el comando que agregue el servidor al dominio, siendo el mismo para los distintos sistemas operativos Linux.  sudo ipa-client-install --mkhomedir --enable-dns-update --principal=systemenrollment --password=&lt;PASSWORD&gt; -U      &lt;PASSWORD&gt; es la contraseña que habéis puesto para dicho usuario.   Ahora os explicaré que significa cada parámetro:     --mkhomedir Crea la carpeta /home/ para los usuarios que inician sesión por primera vez.   --enable-dns-update Permite que haga actualizaciones en el DNS cuando se detecta que la IP de la máquina cambie.   --principal El usuario con el que vamos a unir el equipo.   --password La contraseña del usuario.   -U Para que la instalación sea desatendida, que no requiera interactuación con el usuario.   Una vez hecho todo esto, ya nos aparecerá en nuestro IPA para que podamos acceder con los usuarios que vayamos creando en él.  Esto lo podéis ver en el apartado de Equipos, como muestro a continuación. El nombre del equipo que he usado para este post es freeipa-server02.samurantech.local.   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Patroni en Ubuntu",
    "url": "/posts/instalar-patroni/",
    "categories": "linux, ubuntu, postgres",
    "tags": "linux, ubuntu, postgres",
    "date": "2023-10-27 13:00:00 +0200",
    "content": "En este artículo se documenta cómo realizar la instalación de Patroni, un componente para crear cluster de PostgreSQL con Zookeeper, etcd o Consul. En nuestro caso, utilizaremos etcd, que comenté en el artículo anterior, para ello y HAProxy, esto explicado al final de este mismo artículo, para el balanceo entre los nodos finales.  Previamente tendremos que haber instalado PostgreSQL en cada uno de los nodos en los que se vaya a desplegar Patroni. La instalación se ha realizado sobre 3 nodos Ubuntu 22.04.  Toda esta configuración se está realizando con el usuario root  Vamos a abrir los puertos necesarios en el firewall para que los nodos se puedan comunicar entre ellos y las aplicaciones que posteriormente conectemos contra el clúster:  firewall-cmd --permanent --add-port={5432,8008}/tcp firewall-cmd --reload   Configuramos Watchdog y los permisos necesarios.  cat &lt;&lt;EOF | sudo tee /etc/udev/rules.d/99-watchdog.rules KERNEL==\"watchdog\", OWNER=\"postgres\", GROUP=\"postgres\" EOF  echo \"softdog\" &gt;&gt; /etc/modules-load.d/softdog.conf  modprobe softdog  chown postgres: /dev/watchdog   Tenemos que buscar si Softdog está en la blacklist de modules para que arranque con el servidor.  grep blacklist /lib/modprobe.d/* /etc/modprobe.d/* |grep softdog  # Nos aparecerá el fichero en el que se encuentra, en nuestro caso es \"/lib/modprobe.d/blacklist_linux_5.4.0-148-generic.conf\", y eliminamos la línea \"blacklist softdog\"  # Comprobamos que esté cargado lsmod | grep softdog   Instalamos Patroni en cada uno de los nodos.  apt install -y patroni   Ahora vamos a configurar el componente. De la siguiente manera sólo tendremos que cambiar las IPs de los nodos de etcd a los que se tiene que conectar, propiedades tales como el nombre del host, se hará automáticamente. Con esto será copiar y pegar.  PGPORT=5432 CLUSTER_NAME=\"cluster-1\" MY_NAME=$(hostname --short) MY_IP=$(hostname -I | awk ' {print $1}') cat &lt;&lt;EOF | sudo tee /etc/patroni/config.yml scope: $CLUSTER_NAME namespace: /db/ name: $MY_NAME  restapi:   listen: \"0.0.0.0:8008\"   connect_address: \"$MY_IP:8008\"   authentication:     username: patroni     password: mySuperSecretPassword  etcd3:     hosts:     - &lt;nodo1_etcd&gt;:2379     - &lt;nodo2_etcd&gt;:2379     - &lt;nodo3_etcd&gt;:2379  bootstrap:   dcs:     ttl: 30     loop_wait: 10     retry_timeout: 10     maximum_lag_on_failover: 1048576     postgresql:       use_pg_rewind: true       use_slots: true       parameters:         archive_mode: \"on\"         archive_command: \"/bin/true\"         logging_collector: 'on'    initdb:   - encoding: UTF8   - data-checksums   - auth-local: peer   - auth-host: scram-sha-256    pg_hba:   - host replication replicator 0.0.0.0/0 scram-sha-256   - host all all 0.0.0.0/0 md5    # Some additional users which needs to be created after initializing new cluster   users:     admin:       password: admin%       options:         - createrole         - createdb  postgresql:   listen: \"0.0.0.0:$PGPORT\"   connect_address: \"$MY_IP:$PGPORT\"   data_dir: /data01/pgstorage/   bin_dir: /usr/lib/postgresql/15/bin/   pgpass: /tmp/pgpass0   authentication:     replication:       username: replicator       password: confidential     superuser:       username: postgresql       password: postgres     rewind:       username: rewind_user       password: rewind_password   parameters:     unix_socket_directories: \"/var/run/postgresql/\"  watchdog:   mode: required   device: /dev/watchdog   safety_margin: 5  tags:   nofailover: false   noloadbalance: false   clonefrom: false   nosync: false EOF  systemctl enable --now patroni systemctl restart patroni   Si llegase a fallar la creación automática de los usuarios, habría que crearlos o cambiarles la contraseña manual, metiéndonos con usuario postgres y ejecutando las siguientes queries desde psql.  # Cambiar la contraseña del usuario postgres ALTER USER postgres WITH PASSWORD 'postgres';  # Crear el usuario para la replicación CREATE ROLE replicator WITH REPLICATION LOGIN PASSWORD 'confidential';  # Crear el usuario para el rewind (el streaming de datos) y darle los permisos necesarios CREATE USER rewind_user LOGIN PASSWORD 'rewind_password'; GRANT EXECUTE ON function pg_catalog.pg_ls_dir(text, boolean, boolean) TO rewind_user; GRANT EXECUTE ON function pg_catalog.pg_stat_file(text, boolean) TO rewind_user; GRANT EXECUTE ON function pg_catalog.pg_read_binary_file(text) TO rewind_user; GRANT EXECUTE ON function pg_catalog.pg_read_binary_file(text, bigint, bigint, boolean) TO rewind_user;   Para comprobar que la instalación es correcta, con el siguiente comando podremos listar los nodos que tenemos, su rol, el lag a la hora de replicar entre ellos o si queda pendiente reiniciar alguno de los nodos por configuraciones que hayamos hecho.  patronictl -c /etc/patroni/config.yml list  + Cluster: cluster-1 (7284196933919984482) --------+----+-----------+--------------+ | Member         | Host          | Role         | State     | TL | Lag in MB | Tags         | +----------------+---------------+--------------+-----------+----+-----------+--------------+ | n1-pro         | 10.255.10.121 | Leader       | running   | 31 |           |              | | n2-pro         | 10.255.10.122 | Replica      | streaming | 31 |         0 | nosync: true | | n3-pro         | 10.255.10.123 | Replica      | streaming | 31 |         0 | nosync: true | +----------------+---------------+--------------+-----------+----+-----------+--------------+   HAProxy  Con los pasos realizados anteriormente habremos configurado el cluster de Patroni, ahora configuraremos el HAProxy para que haga el balanceo.  Previamente tendremos que haber instalado HAProxy, en este apartado sólo se mencionará la configuración.  # Hacemos una copia del fichero de configuración y eliminamos el contenido del original cp /etc/haproxy/haproxy.cfg{,.bak} &gt;/etc/haproxy/haproxy.cfg  # Ponemos la configuración correspondiente en el fichero cat&lt;&lt;EOF | tee /etc/haproxy/haproxy.cfg global     maxconn 100  defaults     log    global     mode   tcp     retries 2     timeout client 30m     timeout connect 4s     timeout server 30m     timeout check 5s  listen stats     mode http     bind *:7000     stats enable     stats uri /  listen read-write     bind *:5432     option httpchk OPTIONS /read-write     http-check expect status 200     default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions     server n1-pro 10.255.10.121:5432 maxconn 100 check port 8008     server n2-pro 10.255.10.122:5432 maxconn 100 check port 8008     server n3-pro 10.255.10.123:5432 maxconn 100 check port 8008  listen read-only     balance roundrobin     bind *:5433     option httpchk OPTIONS /replica     http-check expect status 200     default-server inter 3s fall 3 rise 2 on-marked-down shutdown-sessions     server n1-pro 10.255.10.121:5432 maxconn 100 check port 8008     server n2-pro 10.255.10.122:5432 maxconn 100 check port 8008     server n3-pro 10.255.10.123:5432 maxconn 100 check port 8008 EOF   Reiniciamos el servicio de HAProxy y comprobamos en el log si todo está bien.  systemctl restart haproxy; tail -f /var/log/haproxy.log   Si nos conectamos a la IP del Haproxy y al puerto 7000, podremos ver que nodos están en escritura/lectura y cuáles en sólo lectura.  Con esto último ya habremos terminado la configuración por completo. Se pueden hacer más configuraciones como poner que uno de los nodos sea asíncrono con la etiqueta nosync: true o síncrono si lo configuramos como nosync: false  La verdad es que es una herramienta que da mucho juego y nos permite manejar un cluster de postgres de forma muy sencilla.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar etcd en Ubuntu",
    "url": "/posts/instalar-etcd/",
    "categories": "linux, ubuntu, postgres",
    "tags": "linux, ubuntu, postgres",
    "date": "2023-10-24 17:00:00 +0200",
    "content": "En este artículo voy a explicar cómo realizar la instalación de un clúster de ETCD, una BBDD que almacena los datos en formato key-value. La instalación se ha realizado sobre 3 nodos Ubuntu 20.04.  Toda esta configuración se está realizando con el usuario root.  Vamos a abrir los puertos necesarios en el firewall para que los nodos se puedan comunicar entre ellos y las aplicaciones que posteriormente conectemos contra el clúster:  firewall-cmd --permanent --add-port={2379/tcp,2380/tcp} firewall-cmd --reload   Creamos el usuario etcd, que será quien arranque el servicio. Le hemos configurado para que no cree su carpeta home ni le dé permisos que pueda abrir una shell, pues no lo necesita.  useradd --no-create-home -s /bin/false etcd   Creamos las carpetas necesarias y le damos permisos al usuario etcd  mkdir -p /var/lib/etcd/default/ chown etcd: /var/lib/etcd/default/   Ahora vamos a descomprimir el fichero que contiene los ejecutables de etcd que anteriormente nos habremos descargado de la página de las releases Github de ETCD, en nuestro caso lo hemos dejado en /var/tmp. Una vez se ha descomprimido, movemos los ejecutables a la carpeta /usr/bin.  tar xzvf /var/tmp/etcd-v3.4.27-linux-amd64.tar.gz mv etcd-v3.4.27-linux-amd64/etcd* /usr/bin/   Vamos a crear el fichero de servicio para etcd, con el siguiente comando no hace falta editar el fichero, nos deja ya el contenido que le pongamos en el mismo.  cat &gt;/lib/systemd/system/etcd.service&lt;&lt;\\EOF [Unit] Description=etcd - highly-available key value store Documentation=https://github.com/coreos/etcd Documentation=man:etcd After=network.target Wants=network-online.target  [Service] Environment=DAEMON_ARGS= Environment=ETCD_NAME=%H Environment=ETCD_DATA_DIR=/var/lib/etcd/default EnvironmentFile=-/etc/default/%p Type=notify User=etcd PermissionsStartOnly=true #ExecStart=/bin/sh -c \"GOMAXPROCS=$(nproc) /usr/bin/etcd $DAEMON_ARGS\" ExecStart=/usr/bin/etcd $DAEMON_ARGS Restart=on-abnormal #RestartSec=10s LimitNOFILE=65536  [Install] WantedBy=multi-user.target Alias=etcd2.service EOF   Ahora vamos a crear el fichero de configuración de etcd para el nodo 1.  cat &gt;/etc/default/etcd&lt;&lt;\\EOF ETCD_NAME=node-1 ETCD_LISTEN_PEER_URLS=\"http://&lt;IP_nodo1&gt;:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://&lt;IP_nodo1&gt;:2379\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_INITIAL_CLUSTER=\"node-1=http://&lt;IP_nodo1&gt;:2380,node-2=http://&lt;IP_nodo2&gt;:2380,node-3=http://&lt;IP_nodo3&gt;:2380\" ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://&lt;IP_nodo1&gt;:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://&lt;IP_nodo1&gt;:2379\" ETCD_INITIAL_CLUSTER_STATE=new EOF   La configuración para el nodo 2 sería la misma, pero cambiando lo siguiente.  cat &gt;/etc/default/etcd&lt;&lt;\\EOF ETCD_NAME=node-2 ETCD_LISTEN_PEER_URLS=\"http://&lt;IP_nodo2&gt;:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://&lt;IP_nodo2&gt;:2379\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_INITIAL_CLUSTER=\"node-1=http://&lt;IP_nodo1&gt;:2380,node-2=http://&lt;IP_nodo2&gt;:2380,node-3=http://&lt;IP_nodo3&gt;:2380\" ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://&lt;IP_nodo2&gt;:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://&lt;IP_nodo2&gt;:2379\" ETCD_INITIAL_CLUSTER_STATE=new EOF   La configuración para el nodo 3 sería la misma, pero cambiando lo siguiente.  cat &gt;/etc/default/etcd&lt;&lt;\\EOF ETCD_NAME=node-3 ETCD_LISTEN_PEER_URLS=\"http://&lt;IP_nodo3&gt;:2380\" ETCD_LISTEN_CLIENT_URLS=\"http://&lt;IP_nodo3&gt;:2379\" ETCD_INITIAL_CLUSTER_TOKEN=\"etcd-cluster\" ETCD_INITIAL_CLUSTER=\"node-1=http://&lt;IP_nodo1&gt;:2380,node-2=http://&lt;IP_nodo2&gt;:2380,node-3=http://&lt;IP_nodo3&gt;:2380\" ETCD_INITIAL_ADVERTISE_PEER_URLS=\"http://&lt;IP_nodo3&gt;:2380\" ETCD_ADVERTISE_CLIENT_URLS=\"http://&lt;IP_nodo3&gt;:2379\" ETCD_INITIAL_CLUSTER_STATE=new EOF   Lo que cambia de un fichero a otro son las propiedades que apuntan al nodo en el que estamos haciendo la configuración.  Para terminar, sólo nos quedaría aplicar los cambios en el daemon, habilitar el servicio y ver los logs.  systemctl daemon-reload systemctl enable --now etcd.service journalctl -u etcd -f   Con la opción enable --now hacemos que el servicio arranque con el sistema y lo inicia ahora.  Con esto ya tendremos montado nuestro clúster de etcd, donde podremos comprobar los nodos y la salud del mismo con estos comandos. Donde &lt;IP_nodoN&gt; es cualquier nodo del clúster.  etcdctl --endpoints http://&lt;IP_nodoN&gt;:2379 member list --write-out=table etcdctl --endpoints http://&lt;IP_nodoN&gt;:2379 endpoint status --cluster --write-out=table   La verdad es que sólo conocía esta BBDD de oídas porque es con la que trabaja Kubernetes, y ahora entiendo por qué la utiliza. Es muy ligera y la funcionalidad que tiene es impresionante, es mi caso la uso para integrar servicios como Patroni, que haré un artículo más adelante, APISIX u otro servicio.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Barman para Ubuntu",
    "url": "/posts/instalar-barman/",
    "categories": "linux, ubuntu, postgres, backup",
    "tags": "linux, ubuntu, postgres, backup",
    "date": "2023-05-02 10:00:00 +0200",
    "content": "Tener al día los backups es algo muy importante y más si hablamos de BBDD, por eso el día de hoy traigo esta herramienta llamada Barman que funciona con servidores PostgreSQL.  Para este tutorial voy a contar con que ya tengamos un servidor de PostgreSQL montado, para centrarnos únicamente en la instalación de Barman y la configuración que hay que realizar en ambos servidores.  Instalación Barman y barman-cli  Para instalarlo es muy sencillo, sólo tendremos que ejecutar el siguiente comando en el servidor de Barman.  sudo apt update -y &amp;&amp; sudo apt install barman -y   Con esto actualizaremos los repositorios en Ubuntu e instalaremos el paquete sin necesidad de tener que confirma.  Una vez haya terminado, podremos ponernos a editar los ficheros de configuración, que se pueden encontrar bien en /etc/barman.conf o /etc/barman/barman.conf.  Para comprobar que versión tenemos instalada, podemos ejecutar barman --version  Para el servidor de PostgreSQL tendremos que instalar barman-cli de la siguiente manera.  sudo apt update -y &amp;&amp; sudo apt install barman-cli -y   Configuración Barman  En este apartado vamos a hacer la parte tanto que implica el servidor de Barman como en el servidor PostgreSQL.  Autenticación sin contraseña en Barman  Lo primero que hay que hacer es iniciar sesión con el usuario barman y generar un par de claves para la conexión sin contraseña por SSH.  sudo su barman ssh-keygen -t rsa   De esta forma, no tendremos que estar cambiando la contraseña del usuario barman. En el segundo comando, damos siguiente a todo y nos habrá creado el par de claves. Para pasarlos al otro servidor, podemos ejecutar el comando ssh-copy-id pero en ocasiones no tenemos la contraseña del usuario postgres, así que yo lo haré a mano, copiando el contenido del fichero /var/lib/barman/.ssh/id_rsa.pub y dejándolo en el fichero authorized_keys que crearemos cuando configuremos la parte de postgres.  Autenticación sin contraseña en PostgreSQL  Tendremos que hacer lo mismo que hemos realizado en el paso anterior, pero sólo que habrá que iniciar sesión con el usuario postgres en el servidor de PostgreSQL.  sudo su postgres ssh-keygen -t rsa   De igual manera, damos siguiente a todo para que nos cree el par de claves. Por defecto nos dejará las claves en /var/lib/postgres/.ssh/id_rsa.pub  En este punto tendremos que hacer lo siguiente, el contenido del fichero /var/lib/postgres/.ssh/id_rsa.pub del servidor PostgreSQL tendrá que estar en /var/lib/barman/.ssh/authorized_keys y el fichero /var/lib/barman/.ssh/id_rsa.pub en /var/lib/postgres/.ssh/authorized_keys. Con esto podremos hacer que ambos servidores se conecten el uno al otro sin necesidad de poner contraseña.  Algo recomendable por si os salta error es intentar conectarse por ssh del servidor de Barman con el usuario barman al servidor de PostgreSQL y del servidor de PostgreSQL con el usuario postgres al servidor de barman para aceptar la key fingerprint.  Crear rol barman en BBDD  Necesitamos crear un usuario con permisos de superusuario para poder hacer el backup. Para ello, nos conectaremos a nuestra BBDD, ya sea con herramientas como PGAdmin o la propia línea de comandos, psql.  Os dejo el comando a ejecutar para crearlo. La contraseña puede ser la que quiera, que se indica en lo entrecomillado que viene después de password.  postgres=# create user barman superuser password 'barman';   Modificar ficheros configuración Barman  En este apartado vamos a cambiar tanto el fichero general de Barman, como el fichero que hay que crear para la conexión al servidor PostgreSQL.  En el fichero de configuración /etc/barman.conf, vamos a añadir las siguientes líneas, ya sea agregándolas o descomentando las que ya hay.  barman_home = /var/lib/barman # Aquí definimos dónde se guardan los backups compression = gzip parallel_jobs = 2 # Aquí definimos que a la hora de hacer la copia, utilicé 2 jobs en vez de 1 como hace por defecto retention_policy = RECOVERY WINDOW OF 4 WEEKS # Aquí definimos que queremos que mantengan 4 semanas de backups retention_policy_mode = auto   Para el fichero de conexión al servidor que queramos hacer el backup, dentro de la carpeta /etc/barman/conf.d hay templates para poder copiar el fichero y simplemente modificar los datos de conexión. Aquí os dejo uno de ejemplo.  ; Barman, Backup and Recovery Manager for PostgreSQL ; http://www.pgbarman.org/ - http://www.2ndQuadrant.com/ ; ; Template configuration file for a server using ; SSH connections and rsync for copy. ;  [postgres-test] ; Human readable description description =  \"Servidor test Postgres\"  ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; SSH options (mandatory) ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ssh_command = ssh -q postgres@10.1.10.201  ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; PostgreSQL connection string (mandatory) ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; conninfo = host=10.1.10.201 user=barman dbname=postgres  ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; Backup settings (via rsync over SSH) ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; backup_method = rsync ; Incremental backup support: possible values are None (default), link or copy reuse_backup = link ; Identify the standard behavior for backup operations: possible values are ; exclusive_backup (default), concurrent_backup ; concurrent_backup is the preferred method with PostgreSQL &gt;= 9.6 backup_options = exclusive_backup  ; Number of parallel workers to perform file copy during backup and recover parallel_jobs = 2  ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; ; Continuous WAL archiving (via 'archive_command') ; ;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;;; archiver = on ;archiver_batch_size = 50  ; PATH setting for this server path_prefix = \"/usr/pgsql-12/bin\" retention_policy = RECOVERY WINDOW OF 2 WEEKS retention_policy_mode = auto   Comprobar conexión Barman-PostgreSQL  Una vez hecho todo esto, podremos verificar que Barman ha tomado correctamente la configuración que hemos realizado y se conecta al servidor.  Con barman list-server, nos mostrará los servidores que hayamos configurado. Con barman show-server &lt;server&gt;, en este caso cambiamos &lt;server&gt; por postgres-test como he puesto en el fichero de configuración y nos mostrará la configuración para ese servidor.  Con el siguiente comando comprobaremos la conexión, que en este punto nos dará fallo porque todavía queda por configurar los WAL. El comando es cuestión es barman check &lt;server&gt;  Configurar envío WAL a servidor Barman  Hay que modificar los siguientes parámetros en el fichero de configuración postgresql.conf que se encuentra en el servidor PostgreSQL.  archive_mode = on # Prestar especial atención a este, porque si está con otro valor, habrá que reiniciar el servicio archive_command = 'barman-wal-archive 10.1.10.202 10.1.10.201 \"%p\" ' # Siendo la primera IP el servidor de Barman y la segunda el servidor de PostgreSQL. Con este sólo será necesario hacer un reload   Reiniciamos o recargamos el servicio de PostgreSQL según venga al caso y volvemos al servidor de Barman.  En el servidor de Barman ejecutaremos el siguiente comando para forzar que copie los ficheros WALs y comprobar que hemos hecho la configuración correctamente.  barman switch-xlog --force --archive postgres-test   Volvemos a ejecutar el comando barman check postgres-test para confirmar que va a realizar el backup correctamente.  Configuración extra  Para que Barman haga una comprobación del estado de los servidores y se traiga los WALs que estos tengan, hay que hacer una configuración en Crontab del usuario barman.  sudo su barman crontab -e   Ahí podremos configurar que cada minuto haga la comprobación y haga un backup, ya sea completo o incremental según indiquemos. Aquí un ejemplo de ello.  */1 * * * *  barman cron # Cada minuto hará la comprobación que he comentado 00 22 * * 1  barman backup --reuse-backup off postgres-test # Que haga una copia completa los lunes, a las 10 de la noche 00 22 * * 0,2,3,4,5,6  barman backup postgres-test # Que haga una copia incremental el resto de días, a las 10 de la noche   Con todo esto, ya tendremos un backup de nuestros servidores de BBDD, por si fuera necesario algún tener que echar mano de ellos, que esperemos que no.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar FreeIPA Server en Rocky Linux 9",
    "url": "/posts/instalar-freeipa-server-rockylinux/",
    "categories": "linux, rocky, freeipa",
    "tags": "linux, rocky, freeipa",
    "date": "2023-04-01 10:00:00 +0200",
    "content": "Para que nos entendamos con FreeIPA, es como el Active Directory de Windows, pero desde mi punto de vista, mejor porque es en Linux. Con este servicio podremos centralizar la autenticación y autorización a los servidores de nuestra infraestructura, además de poder gestionar certificados, claves SSH (aunque esté incluido en lo que he comentado en lo de autenticación/autorización), poder hacer que se automonte particiones en los servidores, DNS, etcétera… Vamos que vale para muchas cosas que ya iremos viendo.  He elegido Rocky Linux 9 por dos motivos, para Ubuntu sólo hay hasta la versión 18.04 y porque este es el sucesor espiritual de CentOS.  Prerequisitos  Primero que todo vamos a actualizar los repositorios y paquetes del servidor que hayamos desplegado para ello con el siguiente comando:  sudo dnf update -y   Ahora vamos a asegurarnos que la fecha y la hora está bien, además de configurar el nombre del servidor, que tenga una IP estática. En el ejemplo he puesto los datos de mi servidor, pero vosotros tendréis que cambiar la IP y el nombre para que corresponda con el vuestro.  # Cambiar la zona horaria sudo timedatectl set-timezone Europe/Madrid  # Cambiar el nombre del host añadiendo el nombre del dominio sudo hostnamectl set-hostname freeipa-server1.samurantech.local sudo sh -c 'echo \"192.168.122.11 freeipa-server1.samurantech.local freeipa-server1\" &gt;&gt; /etc/hosts'  # Comprobar que los cambios anteriores se hayan efectuado timedatectl &amp;&amp; hostnamectl   Si en el fichero /etc/hosts hay alguna referencia al servidor con la IP 127.0.1.1 o con IPv6, yo recomiendo eliminarlo para que no dé problemas.  Instalación FreeIPA Server  Ahora sí que vamos a empezar con la instalación como tal, por lo que tendremos que ejecutar el siguiente comando para que instale los paquetes necesarios, el servidor, los DNS y el cliente de FreeIPA.  sudo dnf install freeipa-server freeipa-server-dns freeipa-client -y   Una vez terminado, vamos a configurarlo.  Configuración FreeIPA Server  Para instalarlo podríamos simplemente ejecutar el comando ipa-server-install e ir rellenando los datos que nos vayan pidiendo, pero para hacerlo más cómodo vamos a ponerle los siguientes parámetros para que lo configure de una sola vez.  sudo ipa-server-install --ip-address=192.168.122.11 \\ --realm SAMURANTECH.LOCAL \\ --ds-password=DS_PASS \\ --admin-password=ADMIN_PASS \\ --setup-dns \\ --auto-reverse \\ --forwarder 8.8.8.8 \\ --unattended   Ahora os explicaré que significa cada parámetro:     --ip-address Selecciona la IP por dónde queremos que el servidor levante los servicios, si tienes varias IPs en un mismo servidor como es mi caso, es mejor especificar.   --realm Cómo queremos que se llame nuestro dominio de Kerberos, lo recomiendo poner en mayúsculas.   --ds-password La contraseña del Directory Server para el usuario del Directory Manager. Tiene que tener un mínimo de 8 caracteres.   --admin-password La contraseña del usuario administrador. Tiene que tener un mínimo de 8 caracteres.   --setup-dns Para configurar el servidor DNS según hace la configuración.   --auto-reverse Para que cree automáticamente la zona reversa DNS con sus registros PTR.   --forwarder Configurar el reenviador DNS.   --unattended Para que no tenga que pedirnos interactuar con la instalación, que lo haga automáticamente.   Añadir que se puede configurar un CA externo, pero si no se especifica, FreeIPA crea uno propio.     Si os da un error con IPv6 como fue mi caso, tenemos que añadir/modificar en el fichero /etc/sysctl.conf la línea net.ipv6.conf.all.disable_ipv6 = 0 (si veis un 1, hay que poner un 0) y ejecutar sudo sysctl -p para que aplique los cambios sin tener que reiniciar el servidor.   Si tenemos firewalld ejecutándose en nuestro sistema, tendremos que abrir los puertos necesarios para poder acceder:  sudo firewall-cmd --add-service={freeipa-4,dns,ntp} --permanent sudo firewall-cmd --add-port={88/udp,464/udp,464/tcp} --permanent sudo firewall-cmd --reload   El servicio freeipa-4 tiene incluido todos los puertos necesarios como HTTPS, LDAP, LDAPS, Kerberos y Kpasswd (Para más información, puedes mirarlo en /usr/lib/firewalld/services/freeipa-4.xml)  Comprobar que el servicio funciona  Verificamos que los servicios de IPA están corriendo:  [samuel@freeipa-server1 ~]$ sudo ipactl status Directory Service: RUNNING krb5kdc Service: RUNNING kadmin Service: RUNNING named Service: RUNNING httpd Service: RUNNING ipa-custodia Service: RUNNING pki-tomcatd Service: RUNNING ipa-otpd Service: RUNNING ipa-dnskeysyncd Service: RUNNING ipa: INFO: The ipactl command was successful   También podemos conectarnos por https para acceder a su interfaz web, en mi caso https://freeipa-server1.samurantech.local/ipa/ui/  En los siguientes posts veremos cómo crear usuarios desde la web, cómo añadir un cliente al nuestro dominio y crear un segundo servidor para que haya replicación maestro-maestro, entre otros.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Let's Encrypt en CentOS 7 y Ubuntu 20.04",
    "url": "/posts/instalar-letencrypt/",
    "categories": "linux, centos, ubuntu",
    "tags": "linux, centos, ubuntu",
    "date": "2023-03-18 13:00:00 +0100",
    "content": "Configurar HTTPS para cifrar comunicaciones es algo muy importante y con esta herramienta podremos conseguir nuestros propios certificados firmados y gratuitos. Let’s Encrypt para quien no lo sepa, es una CA (Autoridad certificadora) gratuita, automatizada y abierta que nos permite crear lo comentado anteriormente.  Importante, esto sólo es válido si tenemos un dominio público para que Let’s Encrypt pueda comprobar nuestra identidad y un registro DNS publicado, no funciona si queremos trabajar con localhost.  Dependencias para CentOS 7  Sólo indico para CentOS ya que para Ubuntu no es necesario instalar nada previamente, actualizar el sistema con apt update y ya. Actualizamos e instalamos dependencias necesarias. Además de asegurarnos que tenemos disponible epel-release.  yum update -y yum -y install yum-utils   En la Wiki de CentOS te indican cómo activarlo en arquitecturas ARMHFP por si trabajáis en una Raspberry Pi.  Una vez hecho esto, podemos seguir con la instalación.  Instalación Certbot  Instalamos Certbot.  # Para CentOS yum install certbot  # Para Ubuntu apt install certbot   Comprobamos que se ha instalado correctamente ejecutando certbot --version y que nos muestre la versión del programa.  Creación de los certificados  Para obtener únicamente el certificado, ejecutaremos el siguiente comando, reemplazando lo que viene a continuación de -d por nuestro dominio. Aquí pondremos algunos parámetros más, porque el comando puede llegar a ser un poco puñetero si dejamos los valores por defecto.  certbot certonly --manual --preferred-challenges=dns --email=samuran@samurantech.com --agree-tos -d *.samurantech.com   Donde:     certonly, indicamos que queremos descargar el certificado, que nos proporcione los ficheros.   --manual, hacemos que la ejecución sea de forma interactiva, que nos permita realizar cambios en los registros DNS, por ejemplo, antes de continuar con la ejecución del comando.   --preferred-challenges=dns, recomiendo esta opción porque sólo tendremos que crear un registro TXT en nuestro proveedor de DNS para que el comando compruebe que tenemos en propiedad ese dominio. Hay otra opción cambiando dns por http, pero la considero más tediosa al tener que crear un fichero en un servidor, publicarlo a internet y el comando compruebe si existe.   --email=samuran@samurantech.com, la cuenta de correo donde llegarán las notificaciones importantes.   --agree-tos, aceptamos las condiciones de uso y términos.   -d &lt;dominio&gt;, dominio del que queremos obtener un certificado. Con * indicamos que sea un wildcard (comodín para subdominios).   Cuando lo ejecutemos nos aparecerá un registro TXT que tendremos que crear (os generará un valor aleatorio, yo he puesto cualquier valor para el ejemplo):  Please deploy a DNS TXT record under the name _acme-challenge.samurantech.com with the following value:  xxxxxxxxxxxxxxxxxxxxxxxx-xxxxxxxxxxxxxxxxxx  Before continuing, verify the record is deployed.   Una vez creado el registro TXT en nuestro proveedor DNS, daremos a Enter y los servidores de Let’s Encrypt se encargarán de comprobar que eso es así.  Con esto tendremos todos los ficheros necesarios en la carpeta /etc/letsencrypt/live/&lt;dominio&gt;/.  Y como último, no olvidar configurar que los certificados se renueven automáticamente creando una tarea en cron con crontab -e:  00 5 * * * /usr/bin/certbot renew   Esto ejecutará la tarea todos los días a las 5 de la mañana.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar Catalina.out en Tomcat9",
    "url": "/posts/configurar-catalina-tomcat9/",
    "categories": "linux, tomcat",
    "tags": "linux, tomcat",
    "date": "2023-03-11 10:30:00 +0100",
    "content": "Por defecto, Tomcat 9 crea dicho fichero con la fecha al final del nombre (catalina.2022-08-30.log). Para que cree un único fichero catalina.out hay que modificar el fichero /lib/systemd/system/tomcat9.service (si lo hemos instalado por repositorio) añadiendo las siguientes líneas al final del mismo.  # Logging  StandardOutput=append:/var/log/tomcat9/catalina.out StandardError=append:/var/log/tomcat9/catalina.out   Una vez hecho esto, ejecutamos systemctl daemon-reload para que coja los cambios al haber modificado el fichero del servicio y aunque a veces no es necesario porque lo hace automático, reiniciar el servicio de Tomcat9 con systemctl restart tomcat9.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar inotify",
    "url": "/posts/configurar-inotify/",
    "categories": "linux",
    "tags": "linux",
    "date": "2023-03-02 10:30:00 +0100",
    "content": "Inotify es un watcher que vigila un directorio y cuando detecta un evento que nosotros definamos, como que llegue un fichero nuevo (o movido en él) ejecuta una acción. Esto resulta muy útil si queremos que un proceso se ejecute al momento en vez de esperar a cierta hora para que eso se produzca.  Ejemplo de configuración  #!/bin/bash source /etc/scripts/.variables inotifywait -m /home/test/in -e close_write -e moved_to |     while read directory action file; do         if [[ \"$file\" == *.csv ]]; then             curl -X POST -u usuario:$TOKEN_EJEC https://jenkins.samurantech.com:8443/job/batch-procesa-ficheros/buildWithParameters?token=$TOKEN_EJEC -F fileInPath=/in/$file         fi     done   El inotify se queda escuchando en el directorio home/test/in a la espera de un nuevo fichero y cuando termina de copiarse uno con la extensión indicada, en este caso .csv, llama al job de Jenkins que hayamos definido (los próximos artículos meteremos mano a Jenkins), pasándole como parámetro la ruta y el nombre del fichero. Se le pasa también como variables el token para la ejecución del job en un fichero externo, el cual se guarda en el fichero /etc/scripts/.variables  Vamos a guardar el script anterior en un fichero, darle permisos de ejecución con chmod +x &lt;fichero_script&gt;.sh y crearemos un servicio para que se quede ejecutando en segundo plano y arranque junto al sistema.  Creación fichero servicio  Creamos un fichero en /etc/systemd/system/ con el nombre que queramos terminado en .service, en mi caso batch-procesa-ficheros.service.  [Unit] Description=Batch procesa ficheros After=network.target  [Service] ExecStart=/var/opt/scripts/batch-procesa-ficheros.sh  [Install] WantedBy=default.target   Ejecutamos los siguientes comandos para recargar el daemon de Linux y habilitar el servicio creado, además de arrancarlo en el mismo comando.  systemctl daemon-reload &amp;&amp; systemctl enable batch-procesa-ficheros --now   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar HTTPS en Tomcat",
    "url": "/posts/configurar-https-tomcat/",
    "categories": "linux, tomcat, https",
    "tags": "linux, tomcat, https",
    "date": "2023-02-28 19:00:00 +0100",
    "content": "En el artículo anterior hablé de un error al intentar arrancar Tomcat9 y caí en que podría hablar de cómo configurar HTTPS en este servicio. Usaremos certificados PEM, en vez de JKS, ya que pienso que es más cómodo al no tener que generar dicho fichero para esto y que la contraseña se tiene que dejar en el fichero de configuración en texto plano.  Configuración  Para que Tomcat trabaje con HTTPS, en este caso utilizando el puerto 8443, hay que realizar la siguiente configuración, tanto a nivel de los ficheros de Tomcat, como los permisos mínimos que hay que configurar en los certificados.  Hay que descomentar y configurar la ruta de los certificados del siguiente bloque de código que se encuentra en /etc/tomcat/server.xml. En este caso, hemos predefinido que esa sea la ruta donde se almacenen los certificados. En el propio certificado vienen incluido el CA Root y CA Intermedio.  &lt;Connector port=\"8443\" protocol=\"org.apache.coyote.http11.Http11AprProtocol\"                  maxThreads=\"150\" SSLEnabled=\"true\"&gt;           &lt;UpgradeProtocol className=\"org.apache.coyote.http2.Http2Protocol\" /&gt;           &lt;SSLHostConfig&gt;               &lt;Certificate certificateKeyFile=\"/etc/pki/tls/private/private_key.key\"                            certificateFile=\"/etc/pki/tls/certs/certificate.chained.crt\"                            type=\"RSA\" /&gt;           &lt;/SSLHostConfig&gt;   &lt;/Connector&gt;    Los certificados tienen que tener ciertos permisos para que Tomcat pueda trabajar con ellos, pero que no sea accesible para cualquiera.     La clave pública puede tener permisos 644 y que el propietario sea root.   La clave privada tenemos que ponerle permisos 400 tanto al usuario root como al usuario tomcat. Para configurar que otro usuario tenga permisos sobre un fichero, podemos configurarlo con el comando sudo setfacl -m u:tomcat:4 private_key.key   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Tomcat9 no inicia al reiniciar el servidor",
    "url": "/posts/tomcat9-no-inicia/",
    "categories": "linux, tomcat",
    "tags": "linux, tomcat",
    "date": "2023-02-27 15:30:00 +0100",
    "content": "Donde trabajo estamos migrando los servidores con Tomcat 8 a Tomcat 9 y al reiniciar el servidor por completo, nos encontramos con esto, que el servicio no se levanta automáticamente, pero si lo inicias mediante un systemctl restart tomcat9, levanta sin problemas. Para dar más detalles, esto me ocurrió en Ubuntu, con la versión de Tomcat 9 instalada por repositorio.  Solución  El fallo da porque hay que configurar en el fichero del servicio /lib/systemd/system/tomcat9.service el siguiente parámetro: ReadWritePaths=/usr/libexec/tomcat9. Recargamos el daemon para que tome los cambios que hemos realizado en el servicio y a la próxima no vuelva a ocurrir. Esto ocurre porque hay que permitir que pueda leer de esa ruta, donde se encuentra varios scripts para arrancar tomcat9 con el sistema.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar relay Postfix",
    "url": "/posts/configurar-relay-postfix/",
    "categories": "linux",
    "tags": "linux",
    "date": "2023-02-26 17:50:00 +0100",
    "content": "En ocasiones nos interesa que nuestro servidor de correo Postfix utilice un SMTP relay para mandar los emails por otro lado, ya sea por motivos de seguridad o por casos temporales como puede ser en mi caso porque Apple se puso tonto y metían cada dos por tres a mis dominios en sus blacklists.  Configuración  Esta configuración es para que los correos de ciertos dominios, icloud.com y me.com, sean mandados por el relay de GMail.  En el fichero /etc/postfix/main.cf hay que agregar la siguiente línea.  transport_maps = hash:/etc/postfix/bysender   En el fichero mencionado, /etc/postfix/bysender agregamos los dominios que queremos que se mande por el relay de la siguiente manera:  icloud.com      smtp:[smtp-relay.gmail.com]:25 me.com          smtp:[smtp-relay.gmail.com]:25   Ejecutamos el siguiente comando para que Postfix cree el fichero correspondiente y posteriormente, recargamos el servicio.  postmap /etc/postfix/bysender systemctl reload postfix   Con esto, cada vez que un correo de los dominios configurados, se mandarán por el relay definido. En este caso, hay que tener ciertas consideraciones con el relay de GMail, como el limite de correos que se pueden mandar. Info  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Obtener hash de un fichero (Windows/Linux)",
    "url": "/posts/obtener-hash-windows-linux/",
    "categories": "linux, windows",
    "tags": "linux, windows",
    "date": "2023-01-29 18:55:00 +0100",
    "content": "Una cosa muy importante a tener en cuenta cuando descargamos un fichero de internet, es asegurar su integridad, que los datos no hayan sido modificados sin autorización en dicho proceso. Para ello, lo recomendable es comprobar el hash del mismo de las siguientes formas, ya sea para Windows o Linux. También es recomendable comprobar el hash cuando se copia un fichero de un equipo a otro, ya que si hay algún corte en la comunicación, el fichero se queda corrupto.  Windows  Para empezar, nos iremos al Explorador de archivos en Windows 10 y a la ruta donde se encuentre el fichero que queramos comprobar. En la barra de direcciones, escribiremos powershell para abrirlo.    Ejecutamos el siguiente comando y así obtendremos el hash del fichero, en este caso en SHA256, donde &lt;fichero&gt; es el fichero que queremos comprobar.  Get-FileHash -Algorithm SHA256 &lt;fichero&gt;   Normalmente en las webs te suele venir una sección donde te muestre el hash o un fichero con él.  Linux  En Linux tenemos que ir al directorio donde se encuentra el fichero y ejecutamos lo siguiente.  sha256sum &lt;fichero&gt;   Aunque sea un proceso sencillo, hay que tomar la costumbre de comprobar el hash de los ficheros para que no nos cuelen un fichero malicioso o nos volvamos locos intentando instalar un componente y no podamos porque el fichero se haya quedado corrupto por quedarse a medio copiar (cosa que me ha pasado en más de una ocasión).  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Utilizar jekyll en Docker",
    "url": "/posts/jekyll-docker/",
    "categories": "docker, jekyll",
    "tags": "docker, jekyll",
    "date": "2023-01-22 19:55:00 +0100",
    "content": "Para hacer esta web, utilicé Jekyll, un generador de sitios web estáticos que permite crear cada página web a partir de un fichero Markdown. Para que sea mucho más cómodo utilizarlo, usaremos Docker para que sea sólo usar un contenedor y no tener que instalar más cosas en nuestros equipos.  Crear sitio web  Ejecutaremos el siguiente comando para que Docker cree el contenedor y ejecute dentro del mismo el comando que utiliza Jekyll para generar lo que vendrá a ser nuestro blog.  export blog_name=\"blog-test\" docker run --rm --volume \"$PWD:/srv/jekyll\" -it jekyll/jekyll jekyll new $blog_name &amp;&amp; cd $blog_name      El parámetro --rm indica que una vez se ejecuta el contenedor, tiene que eliminarlo. Con -it permite generar una pseudo-terminal, lo que posibilita ejecutar comandos mientras el contenedor se ejecuta.   Nos habrá creado la siguiente estructura de directorios.  blog-test     ├── 404.html     ├── about.markdown     ├── _config.yml     ├── Gemfile     ├── index.markdown     └── _posts         └── 2023-01-22-welcome-to-jekyll.markdown   Construir sitio web  Con esto ya habremos creado nuestro blog, ahora queda construirlo para que Jekyll genere los ficheros necesarios para una vez levantemos el servidor, podamos ver la página como queremos, con sus imágenes y su CSS.  Para ello, tendremos que ejecutar el siguiente comando.  docker run --rm --volume \"$PWD:/srv/jekyll\" -it jekyll/jekyll jekyll build   Esto habrá generado una carpeta llamada _site dentro de nuestro directorio, por lo que ya podremos levantar nuestro servidor para comprobar que funciona correctamente.  Levantar servidor web     Quizás os dé fallo la primera vez que arranque el servidor, para solucionarlo sólo habrá que agregar la siguiente línea en el fichero Gemfile: gem \"webrick\"   Así levantaremos el servidor web para ver la página.  docker run --rm --name blog --volume \"$PWD:/srv/jekyll\" -p 4000:4000 -it jekyll/jekyll jekyll serve   Para mostrarla, tendremos que abrir en el navegador la siguiente dirección, http://localhost:4000. Mientras el servidor esté arrancado, cada vez que hagamos un cambio en los ficheros, con actualizar la página del navegador valdrá para ver el cambio.  Para acabar con el contenedor, valdrá con pulsar ctrl-c para que termine el proceso. Cada vez que queremos levantar el servidor, con volver a ejecutar el anterior comando, lo tendremos listo.  Con esto acaba el post, he utilizado Docker para trabajar con Jekyll porque probé en su día instalarlo directamente en el equipo y el problema de dependencias o al tener que cambiar de un equipo a otro es horrible, por lo que con estos nos ahorraremos muchos quebraderos de cabeza.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Habilitar logs en Rsyslog server",
    "url": "/posts/habilitar-logs-rsyslog-server/",
    "categories": "linux, rsyslog",
    "tags": "linux, rsyslog",
    "date": "2023-01-22 10:15:00 +0100",
    "content": "A veces rsyslog puede dar fallo, pero por defecto, estos logs no vienen habilitados, para ello tendremos que agregar estas líneas en el fichero de configuración rsyslog.conf  $DebugFile &lt;nombre_fichero&gt; $DebugLevel &lt;0|1|2&gt;   Donde &lt;nombre_fichero&gt; es donde queremos que se guarden los logs, podemos poner tanto el nombre de un fichero como la ruta completa con el nombre del fichero. Los niveles de $DebugLevel significan que 0 es desactivado, 1 habilitado el modo debug pero bajo demanda y 2 modo debug activado por completo. Este último tenemos que tener cuidado de no dejarlo activado si se reciben muchos logs, ya que llenará el disco duro en poco tiempo de la cantidad de información que escriben.  Activar modo debug bajo demanda  Si tenemos el nivel 1, para que se escriban logs en el fichero que hemos indicado antes, tenemos que hacer lo siguiente.     Parar el servicio de rsyslog con systemctl stop rsyslog   En otra terminal en el mismo servidor, ejecutar kill -USR1 $(cat /var/run/rsyslogd.pid)   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Ampliar disco LVM",
    "url": "/posts/ampliar-disco-lvm/",
    "categories": "linux, lvm",
    "tags": "linux, lvm",
    "date": "2022-06-01 21:50:00 +0200",
    "content": "Para ampliar el espacio en un disco que ya esté en el servidor, sin añadir un disco duro nuevo, hay que seguir los siguientes pasos.  Añadimos espacio en VWMare al disco. El resto de los pasos ya son dentro del servidor.  Para no tener que reiniciar el servidor para que coja los cambios, ejecutamos el siguiente comando, cambiando la parte de sda por el disco que corresponda:  echo 1 &gt; /sys/class/block/sda/device/rescan`   Con fdisk -l veremos si se ha ampliado el disco. Ahora crearemos la partición.  Utilizando el comando cfdisk /dev/&lt;disco&gt; nos aparecerá un menú para poder hacer la configuración: En este caso lo haremos sobre el disco /dev/sda, que tenía 24GB y le he aumentado en 1GB.       Seleccionamos New, elegimos el tamaño que queremos que tenga dicha partición y si va a ser primary o logical, yo recomiendo que si vamos a ampliar varias veces el disco, escojamos logical ya que la otra opción permite crear pocas.   Seleccionamos Type y elegimos Linux LVM o escribimos el código 8E.   Guardamos los cambios con Write, aplicamos los cambios escribimos yes y salimos con Quit.   Ejecutamos partprobe por si no ha refrescado los cambios.  Ahora creamos el volumen físico para LVM con pvcreate /dev/&lt;partición&gt;, en este caso es /dev/sda4.  Añadimos el volumen físico al grupo, para ver los grupos de discos que existen ejecutamos vgs, con el comando vgextend &lt;vg&gt;/dev/sda4, donde &lt;vg&gt; es el grupo que nos haya mostrado el comando anterior.  Ahora añadimos el espacio al volumen lógico, para ver los volúmenes lógicos que hay ejecutamos lvs y para saber el nombre completo también podemos verlo con df. El formato es algo tal que así /dev/mapper/&lt;vg&gt;-&lt;lv&gt;, &lt;lv&gt; es el resultado del comando lvs. Un ejemplo del comando en cuestión sería lvextend -r -l +100%FREE /dev/mapper/pvg0-lv--root     Es importante tener el -r para que aplique los cambios automáticamente.   Si queremos seleccionar un porcentaje como en el ejemplo, hemos dicho que coja todo el espacio disponible, es con la opción -l (es una L minúscula), en cambio si queremos que sea una cantidad especifica de GB, la opción será -L &lt;nº de GB&gt;GB.   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar Rsyslog para recolectar logs de Docker",
    "url": "/posts/configurar-rsyslog-logs-docker/",
    "categories": "linux, docker, rsyslog",
    "tags": "linux, docker, rsyslog",
    "date": "2022-03-07 18:00:00 +0100",
    "content": "En el post anterior, configuramos un servidor rsyslog para centralizar todos los logs de nuestra infraestructura. En este, configuraremos tanto el servidor Docker que desplegamos para que envíe los logs al rsyslog, como el servidor rsyslog para que los recoja.  Configurar el servidor de rsyslog  Primero vamos a crear un fichero de configuración que recolecte todos los logs del demonio de Docker. Para ello crearemos el fichero /etc/rsyslog.d/docker-daemon.log en el servidor rsyslog con el siguiente contenido:  $template DockerLogs, \"/var/log/docker/daemon.log\"  if $programname startswith 'dockerd' then -?DockerLogs  &amp; stop   Con esto haremos que todo log que empiece por dockerd se guarde en la ruta definida.  Ahora, crearemos el fichero de configuración para los logs de los contenedores, esto también se hará en el servidor rsyslog. El nombre del fichero será /etc/rsyslog.d/docker-containers.log y tendrá lo siguiente:  $template DockerContainerLogs,\"/var/log/docker/%hostname%_%syslogtag:R,ERE,1,ZERO:.*container_name/([^\\[]+)--end%.log\"  if $syslogtag contains 'container_name'  then -?DockerContainerLogs  &amp; stop   Aquí indicamos que guarde en la ruta definida e indique el nombre del host que ha enviado dichos logs.  Reiniciamos el servicio para que se apliquen las configuraciones que acabamos de agregar: systemctl restart rsyslog  Configurar Docker para que envíe los logs a rsyslog  Una vez configurado rsyslog, vamos a configurar el fichero del demonio de Docker, daemon.json, que se encuentra en /etc/docker para servidores Linux y %userprofile%\\.docker en Windows con Docker Desktop.  Tendremos que añadir el siguiente texto a continuación de lo que ya haya en el fichero (he tenido que colocar una imagen porque no reconoce .Name como texto por el formato y lo borra):    Esto etiquetará a todos los contenedores con container_name y el nombre de dicho contenedor para que rsyslog sea capaz de procesarlo según lo hemos indicado anteriormente.  Reiniciamos el servicio de Docker para aplicar cambios: sudo systemctl restart docker  Con esto ya empezarán a llegar los logs de Docker y de los contenedores que ejecute, teniendo de esta forma una manera más cómoda de poder visualizar que puede ocurrir con un contenedor y no tener que acceder a todos los servidores Docker que tengamos en busca de él.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Recolectar cualquier logs con Rsyslog",
    "url": "/posts/configurar-rsyslog-personalizados/",
    "categories": "linux, rsyslog",
    "tags": "linux, rsyslog",
    "date": "2021-03-15 19:35:00 +0100",
    "content": "En esta ocasión, vamos a configurar Rsyslog para que recolecte cualquier log que le indiquemos. Esto es muy útil si tenemos un aplicación propia que genere logs o cualquier otra aplicación como puede ser Tomcat, por ejemplo, además de ser fácil de implementar (una vez te has peleado con ello).  Fichero configuración  Vamos a crear el fichero de configuración necesario en el cliente para que mande los logs al servidor central. El servidor central debe estar configurado como indicamos en este post. Una vez hecho eso, vamos al grano.  Antes de crear el fichero, tenemos que crear el directorio de trabajo para rsyslog, en este caso /var/spool/rsyslog. El comando para ello es: mkdir /var/spool/rsyslog  Creamos un fichero llamado &lt;aplicación&gt;.conf, podéis ponerle el nombre que queráis, dentro de /etc/rsyslog.d/ con el siguiente contenido:  $ModLoad imfile $InputFilePollInterval 10 $WorkDirectory /var/spool/rsyslog  $template Rfc5424Format,\"&lt;%PRI%&gt;1 %TIMESTAMP:::date-rfc3339% %HOSTNAME% %APP-NAME% %PROCID% %MSGID% %STRUCTURED-DATA% %msg%\"  $InputFileName &lt;/ruta/fichero&gt; $InputFileTag &lt;aplicación&gt;-log $InputFileStateFile stat-&lt;aplicación&gt;-log $InputFileSeverity info $InputFilePersistStateInterval 20000 $InputRunFileMonitor if $programname == '&lt;aplicación&gt;-log' then @@&lt;ip_servidor&gt;:514;Rfc5424Format if $programname == '&lt;aplicación&gt;-log' then stop   A primera vista esto asusta un poco, pero vamos a ir desglosando que función tiene cada línea del fichero.  Los siguientes parámetros son globales.     $ModLoad imfile carga el módulo de rsyslog. Lee línea a línea el fichero que le pasemos como parámetro.   $InputFilePollInterval especifica la frecuencia con la que comprueba los archivos para obtener nuevos datos.        $WorkDirectory el directorio de trabajo de rsyslog. Aquí se guardan los llamados state file, que contienen temporalmente los nuevos datos que se recogen para ser enviados.      $template el formato en el que se van a mandar los logs al servidor. Esta parte es muy importante, porque probando distintos formatos, me ha llegado a crear un fichero por cada línea que se recogía en el fichero.   Estos parámetros son específicos para el archivo con que vamos a trabajar.     $InputFileName el fichero que queremos que recolecte la información y envíe.   $InputFileTag el nombre del fichero que se creará en el servidor y donde se mandará la información.   $InputFileStateFile el nombre de los state files mencionados antes.   $InputFileSeverity la severidad que se le asigna a las líneas que lee.   $InputFilePersistStateInterval especifica la frecuencia con la que se escribirá el archivo de estado al procesar el archivo de entrada. Esta configuración se puede utilizar para evitar duplicidad de mensajes por errores como un corte de energía.   $InputRunFileMonitor activa que se monitorice el fichero.   Las dos últimas 2 líneas indican que si les llega una petición de tratar el fichero con el tag indicado, lo manden a un servidor por TCP (2 @ indica TCP, 1 @ por UDP) aplicando el formato que hemos definido.  IMPORTANTE. Si estáis trabajando con CentOS y tenéis el SELinux activado, tenéis que cambiar el tipo del fichero por var_log_t con el comando:  chcon -t var_log_t &lt;fichero&gt;  Tenéis que tener en cuenta que si la carpeta se encuentra fuera de /var/log también tenéis que cambiarle el tipo a dicha carpeta, porque si no rsyslog no podrá acceder a ella.  Puedes jugar bastante con Rsyslog y todas las posibilidades que te ofrece, facilitando mucho el trabajo cuando tienes que revisar muchos logs de distintos servidores.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar servidor Rsyslog en Linux",
    "url": "/posts/configurar-servidor-rsyslog-linux/",
    "categories": "linux, rsyslog",
    "tags": "linux, rsyslog",
    "date": "2021-02-22 10:15:00 +0100",
    "content": "Los logs, esos ficheros que recogen lo que sucede en nuestro sistema y sus aplicaciones, es una parte muy importante en el día a día de nuestro trabajo como sysadmin, pero tener que revisar muchos de estos puede llegar a ser una locura, más ahora que el número de servidores que tenemos que tener bajo control es cada vez más y más grande.  Algo más que recomendable es tener un servidor central que se encargue de recoger estos logs y poder acceder a ellos de forma más cómoda, que no tener que estar revisando uno a uno los servidores encontrando el dichoso fichero.  Por eso hoy os contaré la forma de configurar una forma centralizada de recogida de logs y que en caso de caída del servidor rsyslog, no perdamos ningún fichero guardándolos en el cliente en una cola que los mantenga hasta que sea necesario y enviarlos de nuevo.  Instalar y configurar rsyslog server  Rsyslog es un paquete preinstalado en los sistemas Linux, pero en caso de no tenerlo instalado, podemos obtenerlo de la siguiente manera  yum update -y; yum install rsyslog -y # CentOS 7 apt update -y; apt install rsyslog -y # Ubuntu   Editamos el fichero /etc/rsyslog.conf para configurar que la máquina actúe como servidor.  Descomentamos las siguientes líneas para activar el protocolo UDP y el puerto 514, este último se puede cambiar por otro de nuestra elección.  $ModLoad imudp $UDPServerRun 514   Para las conexiones TCP, debemos descomentar las siguientes líneas, e igual que el anterior, podemos poner un puerto a nuestra elección.  $ModLoad imudp InputTCPServerRun 514   Configuramos una regla para que recoja todos los logs y los guarde en una carpeta con el nombre del host que se lo envía. Para tener una mejor organización y no trabajar sobre el fichero principal, crearemos un fichero remotelogs.conf, aunque se puede llamar como queramos siempre que acabe en .conf dentro de la carpeta /etc/rsyslog.d/  template(name=\"TmplLogRemoto\" type=\"list\") {     constant(value=\"/var/log/rsyslog/\")     property(name=\"HOSTNAME\")     constant(value=\"/\")     property(name=\"programname\" SecurePath=\"replace\")     constant(value=\".log\")     } *.* ?TmplLogRemoto   Lo que hemos hecho es definir que los logs se guarden en /var/log/rsyslog, después tiene que crear una carpeta con el nombre del host por cada cliente que añadamos posteriormente y luego guarde los registros en ella.  Reiniciamos el servicio. systemctl restart rsyslog  Comprobamos que el servidor está a la escucha en los puertos indicados anteriormente. ss -tulnp | grep \"rsyslog\"  Ahora tenemos que permitir las conexiones a esos puertos en firewalld.  firewall-cmd --permanent --add-port=514/udp firewall-cmd --permanent --add-port=514/tcp firewall-cmd --reload   En CentOS, en caso de tener habilitado SELinux, hay que permitir el tráfico de esos puertos, por lo que ejecutaremos los siguientes comandos:  semanage port -a -t syslogd_port_t -p udp 514 semanage port -a -t syslogd_port_t -p tcp 514    Si nos aparece que el comando semanage no existe, tenemos que ejecutar el siguiente comando para poder instalarlo. yum install policycoreutils-python -y  Configurar rsyslog en el cliente  En caso de no tenerlo instalado, hay que seguir los pasos indicados en la parte del servidor, es el mismo paquete.  Como en el caso anterior, para tener una mejor organización, crearemos un fichero en /etc/rsyslog.d llamado como queramos con la extensión .conf, en mi caso clientlogs.conf, y añadimos las siguientes líneas, sustituyendo por la IP del servidor que hemos configurado en el apartado Target.  action(type=\"omfwd\" queue.type=\"LinkedList\" queue.filename=\"queue_logs\" action.resumeRetryCount=\"-1\" queue.saveonshutdown=\"on\" Target=\"&lt;ip_servidor&gt;\" Port=\"514\" Protocol=\"tcp\")   Donde:     queue.type habilita que la cola de logs sea del tipo LinkedList, que asigna la memoria sólo cuando es necesaria.   queue.filename define el nombre del disco que almacenará los logs hasta que se envían al servidor. Se guarda en /var/lib/rsyslog.   action.resumeRetryCount=\"-1\" evita que rsyslog descarte los mensajes al volver a intentar conectarse si el servidor no responde.   queue.saveonshutdown guarda datos en memoria si rsyslog se apaga.   La última línea reenvía todos los mensajes recibidos al servidor por TCP. El puerto es opcional.   Para mandar un custom log y realizar una prueba, si ejecutamos logger &lt;texto&gt;, mandará un log al servidor y comprobaremos si la comunicación se realiza correctamente.  De esta manera, ya tendremos los logs de todos nuestros servidores en un único sitio y no tendremos que estar conectándonos en mil sitios distintos.  En posteriores posts tengo pensado explicar cómo podemos hacer que la comunicación entre servidor/cliente se haga bajo un certificado que cifre la información que se envía, crear templates en los clientes para aplicaciones como Docker, Tomcat y demás, además de desplegar Logstash, Elasticsearch o Kibana para poder trabajar con los logs de forma más visual.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Configurar IP estática en CentOS",
    "url": "/posts/configurar-ip-estatica-centos/",
    "categories": "linux, centos, raspberry pi",
    "tags": "linux, centos, raspberry pi",
    "date": "2021-02-22 10:15:00 +0100",
    "content": "En el post anterior instalamos CentOS en nuestra Raspberry, hoy la configuraremos para poder darle uso.  Normalmente los equipos obtienen su dirección IP a través del protocolo DHCP (Dynamic Network Configuration Protocol), un servicio que proporciona una IP dinámica, además de la máscara de subred, la puerta de enlace y los DNS a los equipos de la red. En redes domésticas quien cumple esta función suele ser el router que nos proporciona nuestro proveedor de internet.  Pero en entornos profesionales, o como es en nuestro caso, no queremos que nuestro servidor tenga un IP que le haya proporcionado el DHCP y que pueda cambiar. Para ello se configura un IP estática o manual y tener bajo control la IP de ese servidor.  Conectarnos al servidor  Podemos acceder al servidor conectando una pantalla y un teclado directamente a la Raspberry Pi y trabajar directamente ahí o podemos conectarnos por SSH.  Para poder conectarnos por SSH, tendremos que averiguar su IP. Podemos saber esto yendo al DHCP del router o hacer un escaneo de red con herramientas como Advanced IP Scanner.  Una vez averiguada la IP, podemos conectarnos por SSH utilizando Putty o MobaXterm, eso os lo dejo al gusto de cada uno. Ponemos la IP del servidor y le ponemos las credenciales, que será el usuario root y la contraseña que hayamos definido.  Configurar la IP estática  Está va a ser la configuración que yo voy a hacer en mi servidor.     Dirección IP: 192.168.0.150 Subred: 255.255.255.0 Puerta de enlace (Router): 192.168.0.1 Servidor DNS 1: 192.168.0.1 Servidor DNS 2: 1.1.1.1   Averiguar interfaces de red en nuestro servidor  Puedes saber las interfaces que tiene el servidor ejecutando el comando:  ifconfig -a   O  ip a   El resultado del comando será parecido a lo que muestro a continuación. En mi caso quiero cambiar la IP a la interfaz eth0, que es la interfaz cableada. lo es la interfaz de loopback, donde está configurado la IP 127.0.0.1 o localhost. wlan0 es la interfaz de conexión inalámbrica, para ir por Wi-FI.  1: lo: &lt;LOOPBACK,UP,LOWER_UP&gt; mtu 65536 qdisc noqueue state UNKNOWN group default qlen 1000     link/loopback 00:00:00:00:00:00 brd 00:00:00:00:00:00     inet 127.0.0.1/8 scope host lo        valid_lft forever preferred_lft forever     inet6 ::1/128 scope host        valid_lft forever preferred_lft forever 2: eth0: &lt;BROADCAST,MULTICAST,UP,LOWER_UP&gt; mtu 1500 qdisc mq state UP group default qlen 1000     link/ether dc:a6:32:a3:a8:b4 brd ff:ff:ff:ff:ff:ff     inet 192.168.0.24/24 brd 192.168.0.255 scope global noprefixroute dynamic eth0        valid_lft 2733sec preferred_lft 2733sec     inet6 fe80::806d:e80d:c6fb:69d6/64 scope link noprefixroute        valid_lft forever preferred_lft forever 3: wlan0: &lt;NO-CARRIER,BROADCAST,MULTICAST,UP&gt; mtu 1500 qdisc pfifo_fast state DOWN group default qlen 1000     link/ether 62:c3:19:db:2a:2c brd ff:ff:ff:ff:ff:ff   Configuración IP estática     Método 1   Para este método, editaremos el fichero de la interfaz de red que se encuentra en el directorio /etc/sysconfig/network-scripts. Para la interfaz eth0, crearemos el fichero ifcfg-eth0.  vi /etc/sysconfig/network-scripts/ifcfg-eth0   El contenido que tenemos que poner en el fichero.  # MAC de la interfaz # HWADDR=dc:a6:32:a3:a8:b4 TYPE=Ethernet BOOTPROTO=none # IP estática # IPADDR=192.168.0.150 # Subred # NETMASK=255.255.255.0 # Puerta de enlace # GATEWAY=192.168.0.1 # Servidores DNS # DNS1=192.168.0.1 DNS2=1.1.1.1 DEFROUTE=yes IPV4_FAILURE_FATAL=no # Deshabilitar ipv6 # IPV6INIT=no # Nombre de la interfaz # NAME=eth0 DEVICE=eth0 # Activar la interfaz en el arranque # ONBOOT=yes      Método 2   También podemos usar nmtui, una interfaz de usuario en texto para configurar interfaces de red.     En caso de no tenerlo instalado, podemos obtenerlo con el comando yum install NetworkManager-tui   nmtui   Seleccionamos Edit a connection y presionamos Enter.    Elegimos la interfaz de red y Edit    Configuramos la IP y le damos a OK    Reiniciamos la red  Finalmente, reiniciamos el servicio de red para que se hagan efectivo los cambios que hemos hecho. Cuando hagamos esto no echará de la sesión porque se ha cambiado de IP.  systemctl restart network   Volvemos a ejecutar el comando ip a para comprobar que el cambio se ha hecho efectivo.  Tip final. Cambiar hostname  Ya que hemos configurado la IP del servidor, vamos a cambiar también el nombre del mismo por alguno más descriptivo y porque personalmente no me gusta que los servidores se llamen localhost.  Aprovechando que hemos trabajado con nmtui, haremos el cambio desde ahí.  Seleccionamos Set system hostname y presionamos Enter.    Ahí ponemos el nombre que queramos que tenga el servidor y presionamos OK.  La gente que quiera hacerlo por comando, tiene a su disposición hostnamectl.  Para cambiar el nombre sería de la siguiente manera:  hostnamectl set-hostname \"&lt;nombre_servidor&gt;\"   Para que se efectúen los cambios podemos bien reiniciar el servidor o el servicio systemctl restart systemd-hostnamed. Para comprobar que el cambio se ha hecho con hostname podremos confirmar que es así. Para el nombre que aparece en la terminal [root@localhost ~]#, con salir de la sesión SSH y volver a conectarnos ya nos aparecerá.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar CentOS en Raspberry Pi",
    "url": "/posts/instalar-centos-raspberry-pi/",
    "categories": "linux, centos, raspberry pi",
    "tags": "linux, centos, raspberry pi",
    "date": "2021-02-21 20:48:00 +0100",
    "content": "Desde hace tiempo tengo varias Raspberry Pi muertas de risa y quiero darles un algún uso, pero no quiero utilizar Raspberry Pi OS, así que instalaremos CentOS 7 para arquitecturas ARM. Como curiosidad, Raspberry Pi OS, antes Raspbian, es el sistema operativo que se suele utilizar en Raspberry Pi basado en Debian.  En caso utilizaré una Raspberry Pi 4 de 4GB de RAM (Enlace artículo Amazon, post no esponsorizado por Amazon).  Descargar CentOS para Raspberry Pi  Primero tendremos que descargarnos la imagen ISO de los repositorios oficiales de CentOS. En esta página tendremos un listado de los mirrors de CentOS, así que elegiremos uno de la lista.  Una vez en el listado tendremos que elegir el fichero que contiene el número 4 en el nombre, indicando que es para la Raspberry Pi 4. Un ejemplo sería CentOS-Userland-7-armv7hl-RaspberryPI-Minimal-4-2009-sda.raw.xz, que contiene Minimal-4. Esta es la opción que no incluye una interfaz gráfica, sólo terminal.  El resto son versiones para la Raspberry Pi 3, tanto la versión minimal como con distintos entornos de escritorio.  Yo elegiré la versión Minimal, porque no me interesa tener un entorno gráfico, ya que me conectaré a través de SSH a ella.  Una vez descargada, comprobamos si el hash del fichero descargado corresponde con el publicado en la página. Normalmente es el fichero que se encuentra en el mismo directorio de donde hemos sacado la ISO llamado sha256sum.txt. En él saldrán los hashes en SHA256 de cada uno de los ficheros.  Para comprobarlo lo haremos de las siguientes maneras dependiendo del sistema operativo.     Windows. Desde una consola de powershell, iremos al directorio donde hemos descargado el fichero y ejecutaremos el siguiente comando:   Get-FileHash &lt;fichero&gt;      Linux. Desde la terminal, iremos al directorio donde hemos descargado el fichero y ejecutaremos el siguiente comando:   sha256sum &lt;fichero&gt;   En este caso usaremos este comando porque queremos obtener el hash SHA256.  Obtenido el hash con el comando, ahora sólo es comparar con el que se muestra en la página. No me seáis cafres y con que comprobéis los primeros 6 dígitos y los 6 últimos valdría.  Montar CentOS en la tarjeta SD  Cuando hayamos descargado la imagen de CentOS y comprobado que el hash es correcto, vamos a montar la ISO en nuestra tarjeta SD. Yo en este caso utilizaré Rufus, pero podéis usar otros como BalenaEtcher. A tener en cuenta: los datos que tengamos en la tarjeta SD se borrarán porque ésta tiene que formatearse.  En caso de que vuestro equipo no tenga lector de tarjetas SD, como me pasa a mí, podéis comprar un lector SD/Micro SD adaptador USB.  Una vez terminado, pondremos la tarjeta en nuestra Raspberry Pi y la conectaremos a la corriente para encenderlo.  Trabajando con CentOS  Para poder conectarnos a nuestra Raspberry Pi directamente, tenemos que tener un adaptador Micro HDMI a HDMI, yo os recomiendo comprar este pack que viene con una carcasa para darle un mejor aspecto.  (Enlace artículo Amazon)  Además de un teclado USB para poder escribir en la terminal.  El usuario por defecto es root. La contraseña por defecto es centos.  Es recomendable cambiar la contraseña, para ello ejecutamos el comando:  passwd   Expandimos la partición de root para que coja el tamaño máximo de la tarjeta SD con rootfs-expand.  Configuramos la zona horaria que corresponda con timedatectl set-timezone Europe/Madrid.  Ahora que hemos hecho esos cambios, vamos a actualizarla e instalar algún paquete. Para manejar los paquetes en CentOS, usamos el comando yum.     Actualizar:   yum update      Instalar:   yum install &lt;nombre_paquete&gt;      Eliminar:   yum remove &lt;nombre_paquete&gt;   Por ejemplo, podemos instalar el editor de texto vim y después eliminarlo de la siguiente manera.  yum install vim yum remove vim   Si al final de estos comandos ponemos la opción -y, no será necesario confirmar que queremos actualizar, instalar o eliminar un paquete.  Con esto podemos dar por finalizado este post, en posteriores posts le daremos uso a la Raspberry y realizarle una configuración más avanzada.  Aporte extra  Trabajando con CentOS en Raspberry Pi por defecto no vienen disponibles los repositorios epel, pero podemos activarlos sin mayor inconveniente. En la Wiki de CentOS te indican cómo activarlo.  Para ello hay que ejecutar lo siguiente:  cat &gt; /etc/yum.repos.d/epel.repo &lt;&lt; EOF [epel] name=Epel rebuild for armhfp baseurl=https://armv7.dev.centos.org/repodir/epel-pass-1/ enabled=1 gpgcheck=0  EOF   Eso creará un fichero indicando que también busque en los repositorios de la URL indicada.  Una vez hecho, actualizamos con yum update -y y ya podremos seguir trabajando.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Docker en Windows",
    "url": "/posts/instalar-docker-windows/",
    "categories": "windows, docker",
    "tags": "windows, docker",
    "date": "2021-02-19 14:55:00 +0100",
    "content": "En el post anterior, aprendimos cómo instalar Docker en un servidor CentOS. En esta ocasión haremos lo propio en un Windows 10, para poder trabajar con la herramienta en nuestro equipo.  Requisitos     Windows 10 64-bit: Pro, Enterprise o Education.   4GB de RAM.   Tener habilitado la virtualización en la BIOS.   En la web oficial de Docker te indican que necesitas tener habilitado el cliente de HyperV, pero como fue en mi caso, al tener habilitado esta característica, aplicaciones como VMware Workstation dejan de funcionar. Por suerte, a partir de Windows 10 2004, salió Windows Subsystem for Linux (WSL) 2, permitiendo correr contenedores Docker de forma nativa, además de reducir el consumo de CPU y memoria de forma considerable.  Para poder seguir este tutorial, tenemos que tener actualizado Windows 10 a la versión 2004 o superior.  Instalación WSL 2  Para poder tener instalado WSL 2, debemos instalar antes la versión 1. Desde una consola de Powershell con permisos de administrador, ejecutamos el siguiente comando:  dism.exe /online /enable-feature /featurename:Microsoft-Windows-Subsystem-Linux /all /norestart   Además tenemos que instalar la característica “Virtual Machine Platform” o su nombre en español “Plataforma de máquina virtual”.  dism.exe /online /enable-feature /featurename:VirtualMachinePlatform /all /norestart   Reiniciamos el equipo y seguimos con el siguiente paso.  En caso de tener ya instalado WSL 1, estos pasos pueden que nos den error. Para actualizar a la versión 2, tenemos que descargar el siguiente paquete de la web de Windows. Una vez descargado, ejecutamos el fichero y seguimos los pasos indicados.  WSL 2 por defecto  Por defecto nuestro sistema utilizará WSL 1, por lo que tenemos que cambiar dicha configuración para que utilice la versión 2. Ejecutamos el siguiente comando en la consola de Powershell.  wsl --set-default-version 2   Para comprobar las distribuciones que tenemos instaladas, podemos hacerlo con el siguiente comando.  wsl -l -v   Instalar y configurar Docker  Ya es hora de instalar Docker después de haber seguido los pasos anteriores. Descargamos Docker Desktop for Windows desde la web de Docker o de Docker Hub y lo instalamos. En la instalación podremos habilitar la compatibilidad con WSL 2 y una vez termine, tendremos que reiniciar el equipo.  Ahora que el equipo haya arrancado e iniciemos Docker Desktop, nos aparecerá una ventana en la aplicación con un tutorial que podemos hacer u omitir.  Para comprobar que todo ha ido bien, abrimos una consola de Powershell y ejecutamos la imagen hello-world como la anterior vez.  docker run hello-world   Es una herramienta muy potente que yo utilizo para realizar desarrollos y pruebas sin tener que desplegar una máquina virtual, ahorrando mucho tiempo en el proceso, por lo cual la recomiendo.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Docker en Ubuntu",
    "url": "/posts/instalar-docker-ubuntu/",
    "categories": "linux, docker, ubuntu",
    "tags": "linux, docker, ubuntu",
    "date": "2021-02-17 15:45:00 +0100",
    "content": "En el post anterior aprendimos a instalar Docker, en este post haremos lo propio Ubuntu. Aunque haya varias maneras de instalarlo, en esta caso utilizaremos la instalación por repositorio.  Paso 1: Eliminar versiones anteriores de Docker  Siempre viene bien hacer una limpieza por si el equipo con el que estamos ya tiene una versión anterior de Docker instalada.  sudo apt remove docker docker-engine docker.io containerd runc   Paso 2: Instalamos dependencias  El siguiente paso es instalar las dependencias que necesita Docker para instalarse.  sudo apt update sudo apt install \\     ca-certificates \\     curl \\     gnupg \\     lsb-release   Paso 3: Configurar el repositorio de Docker  Agregamos la key GPG oficial de Docker.  sudo mkdir -p /etc/apt/keyrings curl -fsSL https://download.docker.com/linux/ubuntu/gpg | sudo gpg --dearmor -o /etc/apt/keyrings/docker.gpg   Con este comando añadimos el repositorio dentro de la carpeta sources.list.d  echo \\   \"deb [arch=$(dpkg --print-architecture) signed-by=/etc/apt/keyrings/docker.gpg] https://download.docker.com/linux/ubuntu \\   $(lsb_release -cs) stable\" | sudo tee /etc/apt/sources.list.d/docker.list &gt; /dev/null   Y actualizamos los repositorios.  sudo apt update   Paso 4: Instalamos Docker CE (Community Edition)  Finalmente, instalamos Docker ejecutando el siguiente comando:  sudo apt-get install docker-ce docker-ce-cli containerd.io docker-compose-plugin   Paso 5: Administrar el servicio de Docker  Aunque hayamos instalado Docker, todavía no se está ejecutando. Tenemos que configurarlo ejecutando los siguientes comandos:     Habilitamos que el servicio inicie con el arranque del servidor:   systemctl enable docker      Iniciamos el servicio de Docker para que empiece a funcionar:   systemctl start docker      Podemos habilitar el servicio y que arranque a la vez si ejecutamos el siguiente comando:   systemctl enable docker --now      Comprobamos que el servicio está iniciado:   systemctl status docker   Nos debería aparecer una línea verde que indica que el servicio está en funcionamiento.  Paso 6: Trabajando con Docker  Tendremos que agregar el usuario con el que hemos instalado Docker al grupo correspondiente para que pueda ejecutar los comandos sin tener que utilizar sudo constantemente.  sudo usermod -aG docker $USER   Una vez hecho esto, vamos a comprobar que Docker funciona correctamente.  docker run hello-world   Con este comando, descargaremos el contenedor hello-world y lo ejecutaremos una vez haya terminado. Si todo ha funcionado correctamente, nos aparecerá el siguiente mensaje:  Hello from Docker! This message shows that your installation appears to be working correctly.  To generate this message, Docker took the following steps:  1. The Docker client contacted the Docker daemon.  2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.     (amd64)  3. The Docker daemon created a new container from that image which runs the     executable that produces the output you are currently reading.  4. The Docker daemon streamed that output to the Docker client, which sent it     to your terminal.  To try something more ambitious, you can run an Ubuntu container with:  $ docker run -it ubuntu bash  Share images, automate workflows, and more with a free Docker ID:  https://hub.docker.com/  For more examples and ideas, visit:  https://docs.docker.com/get-started/   Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Instalar Docker en CentOS",
    "url": "/posts/instalar-docker-centos/",
    "categories": "linux, docker, centos",
    "tags": "linux, docker, centos",
    "date": "2021-02-16 15:45:00 +0100",
    "content": "Hoy hablaremos de una herramienta muy interesante y que cada vez tiene más cabida en nuestro trabajo como sysadmin, Docker. Aprenderemos a instalar Docker en Linux.  Vamos a empezar hablando de lo que es Docker, para tener una idea. Docker es una tecnología de creación de contenedores que permite la creación y el uso de contenedores Linux o Windows. Suelta la explicación que viene en la documentación, seguimos desglosando qué es Docker.  Docker revoluciona el concepto que tenemos de máquinas virtuales, ya no virtualiza un sistema operativo como venimos haciendo desde hace años, lo que hace es virtualizar el software encapsulándolo, gracias a que utiliza características del kernel de Linux, de ahí que se llamen contenedores, haciendo referencia a las cajas de los barcos. Dentro del contenedor se ejecutan todas aquellas cosas que la aplicación necesita para funcionar y la propia aplicación. El contenedor es la aplicación en funcionamiento por así decirlo.  En posts posteriores seguiremos viendo más características del software y explicando cómo se compone, por ahora vamos al lío, que a eso hemos venido.  Paso 1: Actualizar paquetes  En la terminal, escribiremos el siguiente comando para actualizar los repositorios de nuestro servidor:  sudo yum update -y   Paso 2: Instalamos dependencias  El siguiente paso es instalar las dependencias que necesita Docker para instalarse.  sudo yum install yum-utils device-mapper-persistent-data lvm2 -y   Paso 3: Agregamos el repositorio de Docker a CentOS  Por defecto, Docker no viene en los repositorios oficiales de Centos, por lo que tenemos que agregarlos nosotros para poder instalarlo. Instalaremos la versión estable.  sudo yum-config-manager --add-repo https://download.docker.com/linux/centos/docker-ce.repo   Paso 4: Instalamos Docker CE (Community Edition)  Finalmente, instalamos Docker ejecutando el siguiente comando:  sudo yum install docker-ce   Paso 5: Administrar el servicio de Docker  Aunque hayamos instalado Docker, todavía no se está ejecutando. Tenemos que configurarlo ejecutando los siguientes comandos:     Habilitamos que el servicio inicie con el arranque del servidor:   systemctl enable docker      Iniciamos el servicio de Docker para que empiece a funcionar:   systemctl start docker      Comprobamos que el servicio está iniciado:   systemctl status docker   Nos debería aparecer una línea verde que indica que el servicio está en funcionamiento.  Paso 6: Trabajando con Docker  En entornos de laboratorio se suele utilizar el usuario root para poder trabajar cómodamente, pero una buena práctica es darle permisos a un usuario que no sea root sobre el grupo docker. Si estáis usando el usuario al que habéis dado permisos, tenéis que reiniciar la sesión.  sudo usermod -aG docker $USER   Una vez hecho esto, vamos a comprobar que Docker funciona correctamente.  docker run hello-world   Con este comando, descargaremos el contenedor hello-world y lo ejecutaremos una vez haya terminado. Si todo ha funcionado correctamente, nos aparecerá el siguiente mensaje:  Hello from Docker! This message shows that your installation appears to be working correctly.  To generate this message, Docker took the following steps:  1. The Docker client contacted the Docker daemon.  2. The Docker daemon pulled the \"hello-world\" image from the Docker Hub.     (amd64)  3. The Docker daemon created a new container from that image which runs the     executable that produces the output you are currently reading.  4. The Docker daemon streamed that output to the Docker client, which sent it     to your terminal.  To try something more ambitious, you can run an Ubuntu container with:  $ docker run -it ubuntu bash  Share images, automate workflows, and more with a free Docker ID:  https://hub.docker.com/  For more examples and ideas, visit:  https://docs.docker.com/get-started/   En siguientes posts explicaremos más apartados de Docker, como qué son las imágenes, cómo crearlos con Dockerfile, descargarnos imágenes sin ejecutarlas o acceder a los mismos con una consola interactiva.  Espero que os haya gustado y os haya servido de ayuda. ¡Hasta la próxima!"
  },
  
  {
    "title": "Mi primerito post",
    "url": "/posts/mi-primerito-blog/",
    "categories": "Blog",
    "tags": "blog",
    "date": "2021-02-14 22:48:00 +0100",
    "content": "Este es el primer post, espero que el primero de muchos, donde cuento la idea que tengo sobre el blog.  Desde hace tiempo he querido tener una página web propia y subir en ella todas las cosas que sé, ya sea por curiosidad o porque me he tenido que pelear con ellas en el trabajo. La verdad es que no tengo muy claro cómo llevaré esto, la periodicidad de los posts o siquiera si alguien, que no sea un conocido al que le pase el enlace enseñándole lo nuevo que vaya subiendo, llegará a descubrir por casualidad este pequeño blog.  Me haría mucha ilusión que hubiera una persona a la que le resultase de utilidad lo que vaya a escribir, siempre gusta saber que has enseñado algo nuevo a alguien.  Con estas líneas expreso brevemente lo que me ronda por la cabeza respecto a esto. Espero poder escribir muchos posts y que esto vaya viento en popa.  Un saludo. ¡Hasta la próxima!"
  }
  
]

